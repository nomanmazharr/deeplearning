{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89ebde0f-abe6-4154-a633-4d88d890d8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import decode_predictions,preprocess_input\n",
    "import numpy as np \n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2528a7-dbfc-496f-87c6-3616a957c0c9",
   "metadata": {},
   "source": [
    "### Loading Resnet50 and using imagenet weights as it is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c7b556c-6fb4-4c1f-a025-8ad5549de8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet50(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44ff1628-6260-46e3-b88f-122b30be0ce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 65.061    ,  63.221    ,  64.32     ],\n",
       "         [ 65.061    ,  64.221    ,  61.32     ],\n",
       "         [ 74.061    ,  69.221    ,  69.32     ],\n",
       "         ...,\n",
       "         [ 31.060997 ,  25.221    ,  21.32     ],\n",
       "         [ 19.060997 ,  11.221001 ,  13.32     ],\n",
       "         [ 11.060997 ,   3.2210007,   5.3199997]],\n",
       "\n",
       "        [[ 70.061    ,  69.221    ,  68.32     ],\n",
       "         [ 65.061    ,  64.221    ,  63.32     ],\n",
       "         [ 57.060997 ,  54.221    ,  54.32     ],\n",
       "         ...,\n",
       "         [  7.060997 ,   2.2210007,   2.3199997],\n",
       "         [ 26.060997 ,  24.221    ,  25.32     ],\n",
       "         [ 28.060997 ,  25.221    ,  25.32     ]],\n",
       "\n",
       "        [[ 65.061    ,  61.221    ,  57.32     ],\n",
       "         [ 62.060997 ,  60.221    ,  57.32     ],\n",
       "         [ 70.061    ,  66.221    ,  63.32     ],\n",
       "         ...,\n",
       "         [  5.060997 ,   1.2210007,   3.3199997],\n",
       "         [ 13.060997 ,  11.221001 ,  12.32     ],\n",
       "         [ 11.060997 ,  10.221001 ,   7.3199997]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 86.061    ,  79.221    ,  85.32     ],\n",
       "         [ 78.061    ,  72.221    ,  80.32     ],\n",
       "         [ 68.061    ,  60.221    ,  68.32     ],\n",
       "         ...,\n",
       "         [ -5.939003 , -22.779    , -18.68     ],\n",
       "         [  9.060997 ,  -1.7789993,  -0.6800003],\n",
       "         [ 25.060997 ,  14.221001 ,  18.32     ]],\n",
       "\n",
       "        [[ 92.061    ,  85.221    ,  89.32     ],\n",
       "         [100.061    ,  96.221    ,  99.32     ],\n",
       "         [ 93.061    ,  87.221    ,  97.32     ],\n",
       "         ...,\n",
       "         [ 63.060997 ,  49.221    ,  46.32     ],\n",
       "         [ 55.060997 ,  42.221    ,  41.32     ],\n",
       "         [  6.060997 ,  -1.7789993,   0.3199997]],\n",
       "\n",
       "        [[ 78.061    ,  69.221    ,  80.32     ],\n",
       "         [ 90.061    ,  84.221    ,  92.32     ],\n",
       "         [104.061    ,  97.221    , 103.32     ],\n",
       "         ...,\n",
       "         [ 30.060997 ,  16.221    ,  18.32     ],\n",
       "         [ 35.060997 ,  26.221    ,  24.32     ],\n",
       "         [ 52.060997 ,  38.221    ,  40.32     ]]]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_path = 'pexels-pixabay-461064.jpg'\n",
    "img = keras.utils.load_img(img_path, target_size=(224, 224))\n",
    "x = keras.utils.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7882a2b-fa02-48e8-b69b-e3fe40f64c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba39f954-58df-420f-af10-ed11efb38fc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('n03832673', 'notebook', 0.37039545),\n",
       "  ('n03642806', 'laptop', 0.08327617),\n",
       "  ('n06359193', 'web_site', 0.040210165),\n",
       "  ('n03223299', 'doormat', 0.038036287),\n",
       "  ('n03085013', 'computer_keyboard', 0.03181153)]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_predictions(pred,top=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757527fd-ad81-49b3-8b75-d8651636c3d2",
   "metadata": {},
   "source": [
    "### Using PIL to open image and then perform predictions using pre_trained model\n",
    "- Using png image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8a5da135-891b-49bb-a1a1-b41bff50ba16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "image = Image.open('Images/testi_02.png')\n",
    "image = Image.open('Images/')\n",
    "\n",
    "image  = image.resize((128,128))\n",
    "\n",
    "image = image.convert('RGB')\n",
    "x = np.expand_dims(image,axis=0)\n",
    "y = preprocess_input(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dff0f82c-119c-4f51-8e31-bfcd9096ce6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step\n"
     ]
    }
   ],
   "source": [
    "predict = model.predict(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b22b5965-ec94-4e8a-a309-73ea8bfd7ddf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('n03000684', 'chain_saw', 0.8593823),\n",
       "  ('n03970156', 'plunger', 0.07712006),\n",
       "  ('n03692522', 'loupe', 0.017087923)]]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_predictions(predict,top=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74d61e0-053c-447a-9559-18f0833f2bec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
